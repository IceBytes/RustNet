from .scrapers import PacketStorm, CXSecurity, ZeroDay, Vulners, \
    NationaVulnerabilityDB, WpvulndbB
from ..common.writers import write_html, write_txt
from ..common.writers import open_url
from PyQt5.QtCore import *
from PyQt5.QtWidgets import *

NUM_WORKERS = 5
MAX_PRINT_PER_SITE = 30

class FinderThread(QThread):
    finding_output = pyqtSignal(str)

    def __init__(self, keywords, txt_out, html_out):
        super().__init__()
        self.txt_out = txt_out
        self.html_out = html_out
        self.key_words = keywords.split(",")
        self.list_scrapers = [PacketStorm, CXSecurity, Vulners, NationaVulnerabilityDB, WpvulndbB]

    def run(self):
        self.find()
    
    def find(self):
        all_data = {}
        for word_search in self.key_words:
            table_rows = []  
            l_result = []
            l_threads = []
            for scraper_class in self.list_scrapers:
                scraper_instance = scraper_class(word_search)
                scraper_instance.start()
                l_threads.append(scraper_instance)
            [l_result.append({'{0}'.format(th.name_class): th.join()}) for th in l_threads]
            all_data[word_search] = l_result
            for dict_result in l_result:
                count_print = 0
                for key, result in dict_result.items():
                    for exploit_data in result:
                        if count_print > MAX_PRINT_PER_SITE:
                            break
                        count_print += 1
                        self.finding_output.emit("+ {0} | {1} | {2} ".format(exploit_data["date"],
                                                                             str(exploit_data["name"])[0:50],
                                                                             exploit_data["url"]))
                        
                        table_row = f"<tr><td>{exploit_data['date']}</td><td>{exploit_data['name']}</td><td>{exploit_data['url']}</td></tr>"
                        table_rows.append(table_row)

            table_rows_str = "\n".join(table_rows)

            if self.html_out:
                write_html(word_search, table_rows_str)
                open_url('out.html')
            
            if self.txt_out:
                write_txt(all_data)
